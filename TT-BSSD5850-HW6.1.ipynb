{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jjXYwoP26azG"
   },
   "source": [
    "# Character-level text generation with LSTM\n",
    "\n",
    "**Author:** [fchollet](https://twitter.com/fchollet)<br>\n",
    "**Date created:** 2015/06/15<br>\n",
    "**Last modified:** 2020/04/30<br>\n",
    "**Description:** Generate text from Nietzsche's writings with a character-level LSTM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "npNftPFU6azI"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "This example demonstrates how to use a LSTM model to generate\n",
    "text character-by-character.\n",
    "\n",
    "At least 20 epochs are required before the generated text\n",
    "starts sounding locally coherent.\n",
    "\n",
    "It is recommended to run this script on GPU, as recurrent\n",
    "networks are quite computationally intensive.\n",
    "\n",
    "If you try this script on new data, make sure your corpus\n",
    "has at least ~100k characters. ~1M is better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q5sws0VC6azJ"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "iI7cfa636azJ"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tENLsSEW6azK"
   },
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "oCySXn8U6azK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus length: 1115394\n",
      "Total chars: 38\n",
      "Number of sequences: 371785\n"
     ]
    }
   ],
   "source": [
    "# path = keras.utils.get_file(\n",
    "#     \"nietzsche.txt\",\n",
    "#     origin=\"https://s3.amazonaws.com/text-datasets/nietzsche.txt\",\n",
    "# )\n",
    "with io.open(\"input.txt\", encoding=\"utf-8\") as f:\n",
    "    text = f.read().lower()\n",
    "text = text.replace(\"\\n\", \" \")  # We remove newlines chars for nicer display\n",
    "print(\"Corpus length:\", len(text))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "print(\"Total chars:\", len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i : i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print(\"Number of sequences:\", len(sentences))\n",
    "\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=\"bool\")\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=\"bool\")\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fbXID7na6azK"
   },
   "source": [
    "## Build the model: a single LSTM layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "4kXag91t6azK"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(maxlen, len(chars))),\n",
    "        layers.LSTM(128),\n",
    "        layers.Dense(len(chars), activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "optimizer = keras.optimizers.RMSprop(learning_rate=0.01)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KXi6yK8U6azK"
   },
   "source": [
    "## Prepare the text sampling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "0_nS8dv36azL"
   },
   "outputs": [],
   "source": [
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype(\"float64\")\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1-FnEqrn6azL"
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "wm8XUqFC6azL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2905/2905 [==============================] - 175s 60ms/step - loss: 1.3489\n",
      "Epoch 2/5\n",
      "2905/2905 [==============================] - 175s 60ms/step - loss: 1.3549\n",
      "Epoch 3/5\n",
      "2905/2905 [==============================] - 185s 64ms/step - loss: 1.3589\n",
      "Epoch 4/5\n",
      "2905/2905 [==============================] - 184s 63ms/step - loss: 1.3687\n",
      "Epoch 5/5\n",
      "2905/2905 [==============================] - 183s 63ms/step - loss: 1.3501\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x214eb45e560>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "model.fit(x, y, batch_size=batch_size, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Diversity: 0.2\n",
      "...Generating with seed: \" be entreated: tell her i send to her my\"\n",
      "\n",
      "...Generated:   son the streed to him to the man then the strong the house of the prince to the master to the country to the strong the man to the son the rome, the love to the streed to my head to the man that the prince to the man the strend to the streem to the prosperous son that the streep and here is the streed of the stress, the strend to the man and the people to the man the strong to the people to the p\n",
      "-\n",
      "...Diversity: 0.5\n",
      "...Generating with seed: \" be entreated: tell her i send to her my\"\n",
      "\n",
      "...Generated:   soul to do been son here is the prince, there is the mere word of my soul, the poor the perpetious wit-battle, and come to the number to him can strive thee in the day thing in the streem to a streeder and seeming hath conferent with him to the summer and the blest, what had be so much banished with the sweets of her spirit of the infated by the strong for our son but such made him and have to th\n",
      "-\n",
      "...Diversity: 1.0\n",
      "...Generating with seed: \" be entreated: tell her i send to her my\"\n",
      "\n",
      "...Generated:   horse: go your inchieft to live, my deeping vist tewal, my lord, forbooh it!, let rom more man but our buckingham how; buy he send known brothers, what stoly oft.n death is: if you must yond: thood before thim and ones of end to, an blood'd, and full of in'tnoffire upon your eyes of infirsters cold! edward'y forth: mean and avome, to itnother hyoe! then thou traning in his threa plainly sudle kno\n",
      "-\n",
      "...Diversity: 1.2\n",
      "...Generating with seed: \" be entreated: tell her i send to her my\"\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tobit\\AppData\\Local\\Temp\\ipykernel_45608\\436096513.py:4: RuntimeWarning: divide by zero encountered in log\n",
      "  preds = np.log(preds) / temperature\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Generated:   one, awinmifueast you will believe me, for that many trangmis, and while 't-mother.  execern: my tricking their'd by earlys and chefave, that bid the dfie'sh tuven thibsse, son will congod wellich nights me first in hustiminy: hot! thy aride; was not tealling for bynen to tell thee, he am a lane, i hear him! o woman! divy snablish time bidley's unnoldst edward, and answer about me fly in knockll,\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "    print(\"...Diversity:\", diversity)\n",
    "\n",
    "    generated = \"\"\n",
    "    sentence = text[start_index : start_index + maxlen]\n",
    "    print('...Generating with seed: \"' + sentence + '\"')\n",
    "\n",
    "    print()\n",
    "\n",
    "    for i in range(400):\n",
    "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_pred[0, t, char_indices[char]] = 1.0\n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "        next_index = sample(preds, diversity)\n",
    "        next_char = indices_char[next_index]\n",
    "        sentence = sentence[1:] + next_char\n",
    "        generated += next_char\n",
    "\n",
    "        # clear_output(wait=True)\n",
    "        # print(generated)\n",
    "\n",
    "    print(\"...Generated: \", generated)\n",
    "    print(\"-\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: trained_text_gen\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: trained_text_gen\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('trained_text_gen')\n",
    "model.save_weights('trained_text_gen_weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ns, the man be the streets to the street, the bed, and the world and the prince the bed that then the stranger that i think the man be the string the street the rest the bed the contrary of the common and the prince of the princes of the marketh be the descontent the more than the street of the matter than the morn the stries the streets to the mark the more than the bed the street to the man ther\n"
     ]
    }
   ],
   "source": [
    "diversity = 0.2 #only using one diversity\n",
    "text_len = 400 #how much new text to generate\n",
    "generated = \"\"\n",
    "sentence = \"Forecast laptop ratings based on specifications or predict price points\"\n",
    "sentence =  sentence.lower() #format to lowercase\n",
    "sentence = sentence[0:40] #make input be 40 characters long\n",
    "\n",
    "for i in range(text_len):\n",
    "    x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "    for t, char in enumerate(sentence):\n",
    "        x_pred[0, t, char_indices[char]] = 1.0\n",
    "    preds = model.predict(x_pred, verbose=0)[0]\n",
    "    next_index = sample(preds, diversity)\n",
    "    next_char = indices_char[next_index]\n",
    "    sentence = sentence[1:] + next_char\n",
    "    generated += next_char\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "lstm_character_level_text_generation",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
